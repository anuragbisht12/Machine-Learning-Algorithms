{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiLabel Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLu7YlmJIz5vYEguoTIYR7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragbisht12/Machine-Learning-Algorithms/blob/master/MultiLabel_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEJpCe4YkEob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "data, meta = scipy.io.arff.loadarff('/content/Dataset/yeast-train.arff')\n",
        "df_train = pd.DataFrame(data)\n",
        "df_train=df_train.astype(numpy.float64)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNjka4LBzD52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1, meta1 = scipy.io.arff.loadarff('/content/Dataset/yeast-test.arff')\n",
        "df_test = pd.DataFrame(data1)\n",
        "df_test=df_test.astype(numpy.float64)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2tcUQF5wWfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=df_train.iloc[:,-14:-1]\n",
        "X_train=df_train.iloc[:,:103]\n",
        "y_test=df_test.iloc[:,-14:-1]\n",
        "X_test=df_test.iloc[:,:103]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFXgeqwMxKJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "51cb1b6a-a83a-4ba0-955f-908f59657dc4"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Att1', 'Att2', 'Att3', 'Att4', 'Att5', 'Att6', 'Att7', 'Att8', 'Att9',\n",
              "       'Att10',\n",
              "       ...\n",
              "       'Class5', 'Class6', 'Class7', 'Class8', 'Class9', 'Class10', 'Class11',\n",
              "       'Class12', 'Class13', 'Class14'],\n",
              "      dtype='object', length=117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYYdawootJnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e4c356f5-c9ed-4173-f820-b474dd508655"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Att1</th>\n",
              "      <th>Att2</th>\n",
              "      <th>Att3</th>\n",
              "      <th>Att4</th>\n",
              "      <th>Att5</th>\n",
              "      <th>Att6</th>\n",
              "      <th>Att7</th>\n",
              "      <th>Att8</th>\n",
              "      <th>Att9</th>\n",
              "      <th>Att10</th>\n",
              "      <th>Att11</th>\n",
              "      <th>Att12</th>\n",
              "      <th>Att13</th>\n",
              "      <th>Att14</th>\n",
              "      <th>Att15</th>\n",
              "      <th>Att16</th>\n",
              "      <th>Att17</th>\n",
              "      <th>Att18</th>\n",
              "      <th>Att19</th>\n",
              "      <th>Att20</th>\n",
              "      <th>Att21</th>\n",
              "      <th>Att22</th>\n",
              "      <th>Att23</th>\n",
              "      <th>Att24</th>\n",
              "      <th>Att25</th>\n",
              "      <th>Att26</th>\n",
              "      <th>Att27</th>\n",
              "      <th>Att28</th>\n",
              "      <th>Att29</th>\n",
              "      <th>Att30</th>\n",
              "      <th>Att31</th>\n",
              "      <th>Att32</th>\n",
              "      <th>Att33</th>\n",
              "      <th>Att34</th>\n",
              "      <th>Att35</th>\n",
              "      <th>Att36</th>\n",
              "      <th>Att37</th>\n",
              "      <th>Att38</th>\n",
              "      <th>Att39</th>\n",
              "      <th>Att40</th>\n",
              "      <th>...</th>\n",
              "      <th>Att78</th>\n",
              "      <th>Att79</th>\n",
              "      <th>Att80</th>\n",
              "      <th>Att81</th>\n",
              "      <th>Att82</th>\n",
              "      <th>Att83</th>\n",
              "      <th>Att84</th>\n",
              "      <th>Att85</th>\n",
              "      <th>Att86</th>\n",
              "      <th>Att87</th>\n",
              "      <th>Att88</th>\n",
              "      <th>Att89</th>\n",
              "      <th>Att90</th>\n",
              "      <th>Att91</th>\n",
              "      <th>Att92</th>\n",
              "      <th>Att93</th>\n",
              "      <th>Att94</th>\n",
              "      <th>Att95</th>\n",
              "      <th>Att96</th>\n",
              "      <th>Att97</th>\n",
              "      <th>Att98</th>\n",
              "      <th>Att99</th>\n",
              "      <th>Att100</th>\n",
              "      <th>Att101</th>\n",
              "      <th>Att102</th>\n",
              "      <th>Att103</th>\n",
              "      <th>Class1</th>\n",
              "      <th>Class2</th>\n",
              "      <th>Class3</th>\n",
              "      <th>Class4</th>\n",
              "      <th>Class5</th>\n",
              "      <th>Class6</th>\n",
              "      <th>Class7</th>\n",
              "      <th>Class8</th>\n",
              "      <th>Class9</th>\n",
              "      <th>Class10</th>\n",
              "      <th>Class11</th>\n",
              "      <th>Class12</th>\n",
              "      <th>Class13</th>\n",
              "      <th>Class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.093700</td>\n",
              "      <td>0.139771</td>\n",
              "      <td>0.062774</td>\n",
              "      <td>0.007698</td>\n",
              "      <td>0.083873</td>\n",
              "      <td>-0.119156</td>\n",
              "      <td>0.073305</td>\n",
              "      <td>0.005510</td>\n",
              "      <td>0.027523</td>\n",
              "      <td>0.043477</td>\n",
              "      <td>-0.024946</td>\n",
              "      <td>0.061221</td>\n",
              "      <td>0.147377</td>\n",
              "      <td>0.082805</td>\n",
              "      <td>-0.011043</td>\n",
              "      <td>-0.001974</td>\n",
              "      <td>-0.147627</td>\n",
              "      <td>0.123673</td>\n",
              "      <td>0.005631</td>\n",
              "      <td>0.030659</td>\n",
              "      <td>0.005683</td>\n",
              "      <td>0.053414</td>\n",
              "      <td>0.069935</td>\n",
              "      <td>0.033555</td>\n",
              "      <td>0.105394</td>\n",
              "      <td>-0.013519</td>\n",
              "      <td>0.119103</td>\n",
              "      <td>-0.057485</td>\n",
              "      <td>-0.028780</td>\n",
              "      <td>0.144546</td>\n",
              "      <td>0.101353</td>\n",
              "      <td>0.024763</td>\n",
              "      <td>0.011344</td>\n",
              "      <td>0.057414</td>\n",
              "      <td>-0.104664</td>\n",
              "      <td>-0.019050</td>\n",
              "      <td>-0.113221</td>\n",
              "      <td>-0.209969</td>\n",
              "      <td>-0.107153</td>\n",
              "      <td>0.417066</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.081028</td>\n",
              "      <td>0.105889</td>\n",
              "      <td>-0.004947</td>\n",
              "      <td>-0.039124</td>\n",
              "      <td>-0.007124</td>\n",
              "      <td>0.017693</td>\n",
              "      <td>-0.068304</td>\n",
              "      <td>-0.021874</td>\n",
              "      <td>-0.011525</td>\n",
              "      <td>-0.029076</td>\n",
              "      <td>0.026808</td>\n",
              "      <td>-0.043047</td>\n",
              "      <td>0.011630</td>\n",
              "      <td>0.008882</td>\n",
              "      <td>-0.012356</td>\n",
              "      <td>-0.052636</td>\n",
              "      <td>0.039048</td>\n",
              "      <td>-0.018712</td>\n",
              "      <td>-0.034711</td>\n",
              "      <td>-0.038675</td>\n",
              "      <td>-0.039102</td>\n",
              "      <td>0.017429</td>\n",
              "      <td>-0.052659</td>\n",
              "      <td>-0.042402</td>\n",
              "      <td>0.118473</td>\n",
              "      <td>0.125632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.022711</td>\n",
              "      <td>-0.050504</td>\n",
              "      <td>-0.035691</td>\n",
              "      <td>-0.065434</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>-0.378560</td>\n",
              "      <td>0.038212</td>\n",
              "      <td>0.085770</td>\n",
              "      <td>0.182613</td>\n",
              "      <td>-0.055544</td>\n",
              "      <td>0.029267</td>\n",
              "      <td>0.042597</td>\n",
              "      <td>-0.107352</td>\n",
              "      <td>0.019207</td>\n",
              "      <td>0.047062</td>\n",
              "      <td>-0.027285</td>\n",
              "      <td>0.175346</td>\n",
              "      <td>-0.103701</td>\n",
              "      <td>0.012758</td>\n",
              "      <td>0.058121</td>\n",
              "      <td>-0.060435</td>\n",
              "      <td>0.073053</td>\n",
              "      <td>0.046101</td>\n",
              "      <td>-0.039845</td>\n",
              "      <td>0.028614</td>\n",
              "      <td>0.130573</td>\n",
              "      <td>-0.011646</td>\n",
              "      <td>-0.138608</td>\n",
              "      <td>0.072822</td>\n",
              "      <td>-0.008652</td>\n",
              "      <td>-0.092463</td>\n",
              "      <td>-0.018793</td>\n",
              "      <td>0.028554</td>\n",
              "      <td>0.014002</td>\n",
              "      <td>0.047983</td>\n",
              "      <td>0.049252</td>\n",
              "      <td>0.191805</td>\n",
              "      <td>0.212651</td>\n",
              "      <td>0.145249</td>\n",
              "      <td>0.076901</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017657</td>\n",
              "      <td>-0.041264</td>\n",
              "      <td>-0.010627</td>\n",
              "      <td>-0.023341</td>\n",
              "      <td>0.018021</td>\n",
              "      <td>-0.032040</td>\n",
              "      <td>-0.070248</td>\n",
              "      <td>-0.008586</td>\n",
              "      <td>-0.013087</td>\n",
              "      <td>0.006237</td>\n",
              "      <td>-0.035943</td>\n",
              "      <td>-0.022597</td>\n",
              "      <td>-0.044843</td>\n",
              "      <td>-0.042019</td>\n",
              "      <td>-0.003376</td>\n",
              "      <td>0.004003</td>\n",
              "      <td>-0.001198</td>\n",
              "      <td>0.030594</td>\n",
              "      <td>-0.021814</td>\n",
              "      <td>0.010430</td>\n",
              "      <td>-0.013809</td>\n",
              "      <td>-0.009248</td>\n",
              "      <td>-0.027318</td>\n",
              "      <td>-0.014191</td>\n",
              "      <td>0.022783</td>\n",
              "      <td>0.123785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.090407</td>\n",
              "      <td>0.021198</td>\n",
              "      <td>0.208712</td>\n",
              "      <td>0.102752</td>\n",
              "      <td>0.119315</td>\n",
              "      <td>0.041729</td>\n",
              "      <td>-0.021728</td>\n",
              "      <td>0.019603</td>\n",
              "      <td>-0.063853</td>\n",
              "      <td>-0.053756</td>\n",
              "      <td>0.078468</td>\n",
              "      <td>0.130276</td>\n",
              "      <td>0.082742</td>\n",
              "      <td>-0.041696</td>\n",
              "      <td>-0.028589</td>\n",
              "      <td>0.008653</td>\n",
              "      <td>-0.107325</td>\n",
              "      <td>-0.136729</td>\n",
              "      <td>-0.190598</td>\n",
              "      <td>-0.153106</td>\n",
              "      <td>-0.096053</td>\n",
              "      <td>-0.032872</td>\n",
              "      <td>-0.008912</td>\n",
              "      <td>0.042825</td>\n",
              "      <td>0.075615</td>\n",
              "      <td>-0.006747</td>\n",
              "      <td>-0.087992</td>\n",
              "      <td>-0.089286</td>\n",
              "      <td>-0.078429</td>\n",
              "      <td>-0.206253</td>\n",
              "      <td>-0.063610</td>\n",
              "      <td>-0.067006</td>\n",
              "      <td>-0.079174</td>\n",
              "      <td>0.088420</td>\n",
              "      <td>0.094088</td>\n",
              "      <td>-0.091405</td>\n",
              "      <td>-0.102339</td>\n",
              "      <td>-0.121139</td>\n",
              "      <td>-0.072064</td>\n",
              "      <td>0.028891</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007941</td>\n",
              "      <td>0.080493</td>\n",
              "      <td>-0.082171</td>\n",
              "      <td>-0.099567</td>\n",
              "      <td>-0.080164</td>\n",
              "      <td>0.315935</td>\n",
              "      <td>-0.125758</td>\n",
              "      <td>-0.096519</td>\n",
              "      <td>-0.097738</td>\n",
              "      <td>0.255025</td>\n",
              "      <td>-0.064278</td>\n",
              "      <td>-0.057198</td>\n",
              "      <td>0.131774</td>\n",
              "      <td>0.200930</td>\n",
              "      <td>-0.067795</td>\n",
              "      <td>-0.103332</td>\n",
              "      <td>0.195777</td>\n",
              "      <td>0.022294</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>0.002233</td>\n",
              "      <td>-0.002072</td>\n",
              "      <td>-0.010981</td>\n",
              "      <td>0.007615</td>\n",
              "      <td>-0.063378</td>\n",
              "      <td>-0.084181</td>\n",
              "      <td>-0.034402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.085235</td>\n",
              "      <td>0.009540</td>\n",
              "      <td>-0.013228</td>\n",
              "      <td>0.094063</td>\n",
              "      <td>-0.013592</td>\n",
              "      <td>-0.030719</td>\n",
              "      <td>-0.116062</td>\n",
              "      <td>-0.131674</td>\n",
              "      <td>-0.165448</td>\n",
              "      <td>-0.123053</td>\n",
              "      <td>-0.088342</td>\n",
              "      <td>-0.010670</td>\n",
              "      <td>0.030590</td>\n",
              "      <td>0.120052</td>\n",
              "      <td>0.129741</td>\n",
              "      <td>0.105897</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.009029</td>\n",
              "      <td>-0.177667</td>\n",
              "      <td>0.124952</td>\n",
              "      <td>-0.089325</td>\n",
              "      <td>-0.035157</td>\n",
              "      <td>-0.071450</td>\n",
              "      <td>0.006351</td>\n",
              "      <td>0.066697</td>\n",
              "      <td>0.015784</td>\n",
              "      <td>-0.007242</td>\n",
              "      <td>-0.027891</td>\n",
              "      <td>-0.062685</td>\n",
              "      <td>0.072125</td>\n",
              "      <td>0.069402</td>\n",
              "      <td>-0.131082</td>\n",
              "      <td>-0.066887</td>\n",
              "      <td>0.034905</td>\n",
              "      <td>0.075313</td>\n",
              "      <td>-0.020978</td>\n",
              "      <td>-0.091263</td>\n",
              "      <td>-0.141892</td>\n",
              "      <td>-0.075490</td>\n",
              "      <td>-0.135369</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097610</td>\n",
              "      <td>-0.012570</td>\n",
              "      <td>-0.043560</td>\n",
              "      <td>-0.068257</td>\n",
              "      <td>-0.057833</td>\n",
              "      <td>-0.023624</td>\n",
              "      <td>-0.026421</td>\n",
              "      <td>0.002439</td>\n",
              "      <td>0.032469</td>\n",
              "      <td>-0.014280</td>\n",
              "      <td>-0.038554</td>\n",
              "      <td>-0.046454</td>\n",
              "      <td>0.052214</td>\n",
              "      <td>0.043700</td>\n",
              "      <td>0.041239</td>\n",
              "      <td>-0.080285</td>\n",
              "      <td>0.001189</td>\n",
              "      <td>-0.066241</td>\n",
              "      <td>-0.046999</td>\n",
              "      <td>-0.066604</td>\n",
              "      <td>-0.055773</td>\n",
              "      <td>-0.041941</td>\n",
              "      <td>0.051066</td>\n",
              "      <td>0.004976</td>\n",
              "      <td>0.193972</td>\n",
              "      <td>0.131866</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.088765</td>\n",
              "      <td>-0.026743</td>\n",
              "      <td>0.002075</td>\n",
              "      <td>-0.043819</td>\n",
              "      <td>-0.005465</td>\n",
              "      <td>0.004306</td>\n",
              "      <td>-0.055865</td>\n",
              "      <td>-0.071484</td>\n",
              "      <td>-0.159025</td>\n",
              "      <td>-0.111348</td>\n",
              "      <td>-0.113015</td>\n",
              "      <td>-0.151546</td>\n",
              "      <td>-0.224416</td>\n",
              "      <td>-0.193918</td>\n",
              "      <td>-0.097713</td>\n",
              "      <td>-0.078790</td>\n",
              "      <td>-0.045703</td>\n",
              "      <td>0.061530</td>\n",
              "      <td>0.168146</td>\n",
              "      <td>-0.059478</td>\n",
              "      <td>-0.092706</td>\n",
              "      <td>-0.027548</td>\n",
              "      <td>-0.106203</td>\n",
              "      <td>-0.165190</td>\n",
              "      <td>-0.056432</td>\n",
              "      <td>-0.074915</td>\n",
              "      <td>-0.108129</td>\n",
              "      <td>-0.093601</td>\n",
              "      <td>-0.031025</td>\n",
              "      <td>-0.032656</td>\n",
              "      <td>-0.017192</td>\n",
              "      <td>-0.077063</td>\n",
              "      <td>0.074747</td>\n",
              "      <td>0.021375</td>\n",
              "      <td>0.046370</td>\n",
              "      <td>0.144823</td>\n",
              "      <td>0.136922</td>\n",
              "      <td>0.093619</td>\n",
              "      <td>0.127604</td>\n",
              "      <td>-0.027046</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101195</td>\n",
              "      <td>0.025472</td>\n",
              "      <td>-0.067447</td>\n",
              "      <td>-0.060830</td>\n",
              "      <td>-0.037247</td>\n",
              "      <td>0.120840</td>\n",
              "      <td>-0.009208</td>\n",
              "      <td>-0.079342</td>\n",
              "      <td>0.014329</td>\n",
              "      <td>0.044347</td>\n",
              "      <td>-0.018380</td>\n",
              "      <td>-0.029290</td>\n",
              "      <td>0.435292</td>\n",
              "      <td>0.227508</td>\n",
              "      <td>-0.064453</td>\n",
              "      <td>-0.086068</td>\n",
              "      <td>-0.035045</td>\n",
              "      <td>-0.080882</td>\n",
              "      <td>0.028468</td>\n",
              "      <td>-0.073576</td>\n",
              "      <td>0.050630</td>\n",
              "      <td>0.084832</td>\n",
              "      <td>-0.019570</td>\n",
              "      <td>-0.021650</td>\n",
              "      <td>-0.068326</td>\n",
              "      <td>-0.091155</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 117 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Att1      Att2      Att3      Att4  ...  Class11  Class12  Class13  Class14\n",
              "0  0.093700  0.139771  0.062774  0.007698  ...      0.0      0.0      0.0      0.0\n",
              "1 -0.022711 -0.050504 -0.035691 -0.065434  ...      0.0      1.0      1.0      0.0\n",
              "2 -0.090407  0.021198  0.208712  0.102752  ...      0.0      1.0      1.0      0.0\n",
              "3 -0.085235  0.009540 -0.013228  0.094063  ...      0.0      1.0      1.0      1.0\n",
              "4 -0.088765 -0.026743  0.002075 -0.043819  ...      0.0      0.0      0.0      0.0\n",
              "\n",
              "[5 rows x 117 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgEDAQetSP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, Att represents the attributes or the independent variables and Class represents the target variables.\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "\n",
        "# this will generate a random multi-label dataset\n",
        "X, y = make_multilabel_classification(sparse = True, n_labels = 20,\n",
        "return_indicator = 'sparse', allow_unlabeled = False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgAKX3V7thGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sparse: If True, returns a sparse matrix, where sparse matrix means a matrix having a large number of zero elements.\n",
        "\n",
        "# n_labels:  The average number of labels for each instance.\n",
        "\n",
        "# return_indicator: If ‘sparse’ return Y in the sparse binary indicator format.\n",
        "\n",
        "# allow_unlabeled: If True, some instances might not belong to any class."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY9rf2wKtsdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# three methods to solve a multi-label classification problem, namely:\n",
        "\n",
        "# Problem Transformation\n",
        "# Adapted Algorithm\n",
        "# Ensemble approaches"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg0C9cGKu4L7",
        "colab_type": "text"
      },
      "source": [
        "1. Problem Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFmUYxG7u-GU",
        "colab_type": "text"
      },
      "source": [
        "1.1 Binary Relevance:\n",
        "This is the simplest technique, which basically treats each label as a separate single class classification problem. \n",
        " \n",
        "In binary relevance, this problem is broken into 4 different single class classification problems as shown in the figure below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50Hl6LmvROq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4772db29-a642-4ca0-a562-9943876fa6d9"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.8MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93Q15YwvIET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using binary relevance\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# initialize binary relevance multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = BinaryRelevance(GaussianNB())\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFydNQE4vOYP",
        "colab_type": "text"
      },
      "source": [
        "we can’t simply use our normal metrics to calculate the accuracy of our predictions. For that purpose, we will use accuracy score metric. This function calculates subset accuracy meaning the predicted set of labels should exactly match with the true set of labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebpU5xo8u7SQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45f1960d-1fd5-471e-e54d-e90bc86fb35d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10468920392584515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhita789ztQ6",
        "colab_type": "text"
      },
      "source": [
        "**1.2 Classifier Chains**\n",
        "the first classifier is trained just on the input data and then each next classifier is trained on the input space and all the previous classifiers in the chain.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bEz7prPu3xK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23c775f8-c232-453a-b6bc-4986ea8322f8"
      },
      "source": [
        "# using classifier chains\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# initialize classifier chains multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = ClassifierChain(GaussianNB())\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11777535441657579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM07RLAu0ANt",
        "colab_type": "text"
      },
      "source": [
        "**1.3 Label Powerset**\n",
        "we transform the problem into a multi-class problem with one multi-class classifier is trained on all unique label combinations found in the training data.\n",
        "All the multilabel columns are combined to form a multiclass column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_9rlEMX0eHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "076821b3-eab1-402e-d5bb-48fdd56d1f23"
      },
      "source": [
        "# using Label Powerset\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# initialize Label Powerset multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = LabelPowerset(GaussianNB())\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18865866957470012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVcsYG6q0qP0",
        "colab_type": "text"
      },
      "source": [
        "The only disadvantage of this is that as the training data increases, number of classes become more. Thus, increasing the model complexity, and would result in a lower accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mssb5w91012u",
        "colab_type": "text"
      },
      "source": [
        "**2. Adapted Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lBt-rLR0_Oy",
        "colab_type": "text"
      },
      "source": [
        "adapting the algorithm to directly perform multi-label classification, rather than transforming the problem into different subsets of problems.\n",
        "\n",
        "For example, multi-label version of kNN is represented by MLkNN. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR2OEcCR0h6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0892fe47-0e4e-440b-cd97-1688bc340592"
      },
      "source": [
        "from skmultilearn.adapt import MLkNN\n",
        "\n",
        "classifier = MLkNN(k=20)\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1821155943293348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYrEf8K-23ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "b1cfe9da-e412-4318-bc27-4bb52bf644a9"
      },
      "source": [
        "# Another example using adapted algorithm\n",
        "\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from scipy import sparse\n",
        "from skmultilearn.dataset import load_dataset\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "X_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
        "X_test, y_test, _, _ =load_dataset('emotions', 'test')\n",
        "\n",
        "clf = MLkNN(k=5)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(type(y_pred))  # <class 'scipy.sparse.lil.lil_matrix'>\n",
        "\n",
        "print(type(y_pred.toarray()))  # <class 'numpy.ndarray'>\n",
        "\n",
        "y_pred_csr = sparse.csr_matrix(y_pred)\n",
        "\n",
        "print(type(y_pred_csr))  # <class 'scipy.sparse.csr.csr_matrix'>\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(accuracy)  # 0.148"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emotions:train - does not exists downloading\n",
            "Downloaded emotions-train\n",
            "emotions:test - does not exists downloading\n",
            "Downloaded emotions-test\n",
            "<class 'scipy.sparse.lil.lil_matrix'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "0.1485148514851485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A4BESa96Kvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# More at http://scikit.ml/multilabelembeddings.html"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}